{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rsilvei7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "import os\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction\n",
    "Loads a dataset with product data from a specified path available in the environment variable DATASET_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>query</th>\n",
       "      <th>search_page</th>\n",
       "      <th>position</th>\n",
       "      <th>title</th>\n",
       "      <th>concatenated_tags</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>express_delivery</th>\n",
       "      <th>minimum_quantity</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>order_counts</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11394449</td>\n",
       "      <td>8324141</td>\n",
       "      <td>espirito santo</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Mandala Espírito Santo</td>\n",
       "      <td>mandala mdf</td>\n",
       "      <td>2015-11-14 19:42:12</td>\n",
       "      <td>171.89</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Decoração</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15534262</td>\n",
       "      <td>6939286</td>\n",
       "      <td>cartao de visita</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Cartão de Visita</td>\n",
       "      <td>cartao visita panfletos tag adesivos copos lon...</td>\n",
       "      <td>2018-04-04 20:55:07</td>\n",
       "      <td>77.67</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Papel e Cia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  seller_id             query  search_page  position  \\\n",
       "0    11394449    8324141    espirito santo            2         6   \n",
       "1    15534262    6939286  cartao de visita            2         0   \n",
       "\n",
       "                    title                                  concatenated_tags  \\\n",
       "0  Mandala Espírito Santo                                        mandala mdf   \n",
       "1        Cartão de Visita  cartao visita panfletos tag adesivos copos lon...   \n",
       "\n",
       "         creation_date   price  weight  express_delivery  minimum_quantity  \\\n",
       "0  2015-11-14 19:42:12  171.89  1200.0                 1                 4   \n",
       "1  2018-04-04 20:55:07   77.67     8.0                 1                 5   \n",
       "\n",
       "   view_counts  order_counts     category  \n",
       "0          244           NaN    Decoração  \n",
       "1          124           NaN  Papel e Cia  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    DATASET_PATH = os.environ['DATASET_PATH']\n",
    "except:\n",
    "    DATASET_PATH = 'data/sample_products.csv'\n",
    "\n",
    "df_file = pd.read_csv(DATASET_PATH, sep=',')\n",
    "df_file.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data formatting\n",
    "Processes the dataset to use it for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id               0\n",
       "seller_id                0\n",
       "query                    0\n",
       "search_page              0\n",
       "position                 0\n",
       "title                    0\n",
       "concatenated_tags        2\n",
       "creation_date            0\n",
       "price                    0\n",
       "weight                  58\n",
       "express_delivery         0\n",
       "minimum_quantity         0\n",
       "view_counts              0\n",
       "order_counts         20105\n",
       "category                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_file.copy()\n",
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>query</th>\n",
       "      <th>search_page</th>\n",
       "      <th>position</th>\n",
       "      <th>title</th>\n",
       "      <th>concatenated_tags</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>express_delivery</th>\n",
       "      <th>minimum_quantity</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>order_counts</th>\n",
       "      <th>category</th>\n",
       "      <th>cod_category</th>\n",
       "      <th>text_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11394449</td>\n",
       "      <td>8324141</td>\n",
       "      <td>espirito santo</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Mandala Espírito Santo</td>\n",
       "      <td>mandala mdf</td>\n",
       "      <td>2015-11-14 19:42:12</td>\n",
       "      <td>171.89</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Decoração</td>\n",
       "      <td>2</td>\n",
       "      <td>espirito santo Mandala Espírito Santo mandala mdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15534262</td>\n",
       "      <td>6939286</td>\n",
       "      <td>cartao de visita</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Cartão de Visita</td>\n",
       "      <td>cartao visita panfletos tag adesivos copos lon...</td>\n",
       "      <td>2018-04-04 20:55:07</td>\n",
       "      <td>77.67</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Papel e Cia</td>\n",
       "      <td>5</td>\n",
       "      <td>cartao de visita Cartão de Visita cartao visit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  seller_id             query  search_page  position  \\\n",
       "0    11394449    8324141    espirito santo            2         6   \n",
       "1    15534262    6939286  cartao de visita            2         0   \n",
       "\n",
       "                    title                                  concatenated_tags  \\\n",
       "0  Mandala Espírito Santo                                        mandala mdf   \n",
       "1        Cartão de Visita  cartao visita panfletos tag adesivos copos lon...   \n",
       "\n",
       "         creation_date   price  weight  express_delivery  minimum_quantity  \\\n",
       "0  2015-11-14 19:42:12  171.89  1200.0                 1                 4   \n",
       "1  2018-04-04 20:55:07   77.67     8.0                 1                 5   \n",
       "\n",
       "   view_counts  order_counts     category  cod_category  \\\n",
       "0          244           NaN    Decoração             2   \n",
       "1          124           NaN  Papel e Cia             5   \n",
       "\n",
       "                                          text_train  \n",
       "0  espirito santo Mandala Espírito Santo mandala mdf  \n",
       "1  cartao de visita Cartão de Visita cartao visit...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label encoder, using only text columns\n",
    "LE = LabelEncoder()\n",
    "df_data['cod_category'] = LE.fit_transform(df_data['category'])\n",
    "df_data['text_train'] = df_data['query'] +' ' + df_data['title'] + ' ' + df_data['concatenated_tags']\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Specifies a model to handle the categorization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25460,)\n",
      "(12540,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df_data, random_state=42, test_size=0.33, shuffle=True)\n",
    "X_train = train.text_train\n",
    "X_test = test.text_train\n",
    "y_train = train['cod_category']\n",
    "y_test = test['cod_category']\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      2283\n",
      "           1       0.97      0.88      0.92       297\n",
      "           2       0.88      0.90      0.89      2856\n",
      "           3       0.86      0.95      0.90      5805\n",
      "           4       0.91      0.51      0.66       367\n",
      "           5       0.85      0.61      0.71       932\n",
      "\n",
      "    accuracy                           0.87     12540\n",
      "   macro avg       0.89      0.78      0.82     12540\n",
      "weighted avg       0.87      0.87      0.87     12540\n",
      "\n",
      "0.8741626794258374\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression #########\n",
    "LR_Pipe = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1))\n",
    "           ])\n",
    "LR_Pipe.fit(X_train.values.astype('U'), y_train)\n",
    "y_pred = LR_Pipe.predict(X_test.values.astype('U'))\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      2283\n",
      "           1       0.97      0.88      0.92       297\n",
      "           2       0.88      0.90      0.89      2856\n",
      "           3       0.86      0.95      0.90      5805\n",
      "           4       0.91      0.51      0.66       367\n",
      "           5       0.85      0.61      0.71       932\n",
      "\n",
      "    accuracy                           0.87     12540\n",
      "   macro avg       0.89      0.78      0.82     12540\n",
      "weighted avg       0.87      0.87      0.87     12540\n",
      "\n",
      "0.8741626794258374\n"
     ]
    }
   ],
   "source": [
    "#Random Forest ###############\n",
    "RF_Pipe = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(RandomForestClassifier(n_estimators=10, random_state=0), n_jobs=1)),\n",
    "           ])\n",
    "RF_Pipe.fit(X_train.values.astype('U'), y_train)\n",
    "y_pred2 = LR_Pipe.predict(X_test.values.astype('U'))\n",
    "\n",
    "print(classification_report(y_test,y_pred2))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation\n",
    "Generates metrics about the model accuracy (precision, recall, F1, etc.) for each category and exports them to a specified path available in the environment variable METRICS_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    METRICS_PATH = os.environ['METRICS_PATH']\n",
    "except:\n",
    "    METRICS_PATH = 'metrics.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorias = df_data[['cod_category', 'category']].copy()\n",
    "df_categorias = df_categorias.drop_duplicates()\n",
    "categories = df_categorias['category'].tolist()\n",
    "\n",
    "def test_predict(Model, Save, txt):    \n",
    "    metric_file =''\n",
    "    metric_file += '####################################\\n'\n",
    "    metric_file += txt + '\\n'\n",
    "    metric_file += '####################################\\n'\n",
    "        \n",
    "    for cat in categories:    \n",
    "        x_cat_test = test['text_train'][test['category']==cat]\n",
    "        y_cat_test = test['cod_category'][test['category']==cat]\n",
    "        y_pred = Model.predict(x_cat_test)\n",
    "        print('ACC: ',cat, accuracy_score(y_cat_test, y_pred))        \n",
    "        metric_file += 'Category: ' + cat + ' - ACC:' + str(accuracy_score(y_cat_test, y_pred))  + '\\n'\n",
    "        metric_file += str(classification_report(y_cat_test,y_pred)) + '\\n'\n",
    "        print(classification_report(y_cat_test,y_pred))\n",
    "    \n",
    "    if Save == 1:                        \n",
    "        f = open(METRICS_PATH, \"a\")        \n",
    "        f.truncate(0) # need '0' when using r+\n",
    "        f.write(metric_file)\n",
    "        f.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Random Forest Metrics for categories #################\n",
      "ACC:  Decoração 0.8967086834733894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.90      0.95      2856\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      2856\n",
      "   macro avg       0.17      0.15      0.16      2856\n",
      "weighted avg       1.00      0.90      0.95      2856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsilvei7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  Papel e Cia 0.7274678111587983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      0.73      0.84       932\n",
      "\n",
      "    accuracy                           0.73       932\n",
      "   macro avg       0.17      0.12      0.14       932\n",
      "weighted avg       1.00      0.73      0.84       932\n",
      "\n",
      "ACC:  Outros 0.670299727520436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.67      0.80       367\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67       367\n",
      "   macro avg       0.17      0.11      0.13       367\n",
      "weighted avg       1.00      0.67      0.80       367\n",
      "\n",
      "ACC:  Bebê 0.8550153307052124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92      2283\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86      2283\n",
      "   macro avg       0.20      0.17      0.18      2283\n",
      "weighted avg       1.00      0.86      0.92      2283\n",
      "\n",
      "ACC:  Lembrancinhas 0.9608957795004307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      0.96      0.98      5805\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.96      5805\n",
      "   macro avg       0.17      0.16      0.16      5805\n",
      "weighted avg       1.00      0.96      0.98      5805\n",
      "\n",
      "ACC:  Bijuterias e Jóias 0.9292929292929293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.93      0.96       297\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       297\n",
      "   macro avg       0.17      0.15      0.16       297\n",
      "weighted avg       1.00      0.93      0.96       297\n",
      "\n",
      "############### Logistic Regression Metrics for categories #################\n",
      "ACC:  Decoração 0.8960084033613446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.90      0.95      2856\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      2856\n",
      "   macro avg       0.17      0.15      0.16      2856\n",
      "weighted avg       1.00      0.90      0.95      2856\n",
      "\n",
      "ACC:  Papel e Cia 0.6148068669527897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      0.61      0.76       932\n",
      "\n",
      "    accuracy                           0.61       932\n",
      "   macro avg       0.17      0.10      0.13       932\n",
      "weighted avg       1.00      0.61      0.76       932\n",
      "\n",
      "ACC:  Outros 0.5149863760217984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.51      0.68       367\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       367\n",
      "   macro avg       0.17      0.09      0.11       367\n",
      "weighted avg       1.00      0.51      0.68       367\n",
      "\n",
      "ACC:  Bebê 0.8226018396846255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90      2283\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82      2283\n",
      "   macro avg       0.17      0.14      0.15      2283\n",
      "weighted avg       1.00      0.82      0.90      2283\n",
      "\n",
      "ACC:  Lembrancinhas 0.9479758828596038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      0.95      0.97      5805\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95      5805\n",
      "   macro avg       0.17      0.16      0.16      5805\n",
      "weighted avg       1.00      0.95      0.97      5805\n",
      "\n",
      "ACC:  Bijuterias e Jóias 0.8754208754208754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.88      0.93       297\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88       297\n",
      "   macro avg       0.25      0.22      0.23       297\n",
      "weighted avg       1.00      0.88      0.93       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('############### Random Forest Metrics for categories #################')\n",
    "test_predict(RF_Pipe, 0, 'Random Forest - Metrics for categories')\n",
    "\n",
    "print('############### Logistic Regression Metrics for categories #################')\n",
    "test_predict(LR_Pipe, 1, 'Logistic Regression - Metrics for categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model exportation\n",
    "Exports a candidate model to a specified path available in the environment variable MODEL_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "classifier = RF_Pipe\n",
    "\n",
    "try:\n",
    "    MODEL_PATH = os.environ['MODEL_PATH']\n",
    "except:\n",
    "    MODEL_PATH = 'model.pkl'\n",
    "\n",
    "with open(MODEL_PATH, 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
